{
 "cells": [
  {
   "source": [
    "# This jupyter notebook scrapes unstructured data from the website \"The Political Graveyard\" (www.thepoliticalgraveyard.com) into an excel spreadsheet\n",
    "## The historical dataset that is generates is about all religious politicians born in the United States by their religion, birth state and county as well as lived state.\n",
    "### You will need to download chromedriver to exceute this notebook"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import requests"
   ]
  },
  {
   "source": [
    "### Create a dataset for religion, state of residence, birth state and birth county for each politician"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using Selenium for web-scraping\n",
    "\n",
    "# add the location for chromedriver her\n",
    "EXE_PATH = r'C:\\Users\\nikhi\\Desktop\\Summer 2020\\RA Work\\Scraping\\chromedriver.exe'\n",
    "browser = webdriver.Chrome(executable_path=EXE_PATH)\n",
    "\n",
    "# the following religious denominations have their data arranged statewise\n",
    "religion1 = ['Methodist', 'Catholic', 'Presbyterian' , 'Episcopalian', 'Baptist', 'Congregationalist', 'Jewish', 'Lutheran', 'Unitarian', 'Protestant', 'Christian', 'Mormon', 'Disciples of Christ', 'Quaker', 'Christian Reformed']\n",
    "\n",
    "# the following religious denominations have their data all in the same webpage\n",
    "religion2=['Church of Christ', 'Eastern Orthodox', 'Christian Scientist', 'Pentecostal', 'Brethren', 'Atheist or agnostic', 'Muslim', 'Swedenborgian', 'Adventist', 'Nazarene', 'Mennonite', 'Spiritualist', 'Buddhist' , 'Puritan' , 'Deist', 'Scientologist', 'Hindu']\n",
    "\n",
    "# a dictionary for data entries\n",
    "dic_pol_name_state_rel = {}\n",
    "\n",
    "# counter for dictionary entry\n",
    "count = 0\n",
    "\n",
    "# loop over each religion\n",
    "for rel in religion1:\n",
    "\n",
    "    url = \"http://politicalgraveyard.com/index.html#PE\"\n",
    "    \n",
    "    # opne the link to the webpage\n",
    "    browser.get(url)\n",
    "    browser.implicitly_wait(5)\n",
    "\n",
    "    # click on the link whose text contains name of the religion\n",
    "    rel_link = browser.find_element_by_link_text(rel).click()\n",
    "\n",
    "    # get the URL of the link\n",
    "    rel_url = browser.current_url\n",
    "\n",
    "    html = urlopen(rel_url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    # get all the links in that reigion's webpage\n",
    "    link = soup.findAll('a')\n",
    "\n",
    "    # a list of all the links for various states for that religion \n",
    "    state_links=[]\n",
    "\n",
    "    # loop over all the links in that religion's webpage\n",
    "    # the strategy is to keep opening the 'geo' links until 'The Political Grveyard' link appears \n",
    "    # when the loop breaks\n",
    "\n",
    "    for each in link:\n",
    "        if('The Political Graveyard' in each.text):\n",
    "            break\n",
    "        elif(('geo' in each.get('href')) == True):\n",
    "            # get the link for the states and append to the list\n",
    "            state_links.append(each.get('href'))\n",
    "\n",
    "    # loop over all the 'geo' links in that religion's webpage\n",
    "    # the strategy is to keep opening the 'geo' links and extract \n",
    "    # state name and politician's name from the webpage\n",
    "\n",
    "    for st in state_links:\n",
    "        try:\n",
    "            html = requests.get(st)\n",
    "            soup = BeautifulSoup(html.content)\n",
    "\n",
    "            # identifier for state name\n",
    "            a = 'Politicians in'\n",
    "\n",
    "            # loop over all the <\\p> tags to identify state's name in each webpage\n",
    "            for x in (soup.find_all('p')):\n",
    "                if rel in ['Episcopalian', 'Congregationalist', 'Jewish', 'Protestant', 'Mormon', 'Quaker', 'Christian Reformed']:\n",
    "                    # in these religions, the text contains additional religion information that we do not want in the state name\n",
    "                    # we substring accordingly\n",
    "                    state = str(x)[str(x).find(a)+15:str(x).find('<br/>',str(x).find(a)+15)]\n",
    "                else: \n",
    "                    state = str(x)[str(x).find(a)+15:str(x).find('</p>')]\n",
    "\n",
    "            # open the state link\n",
    "            browser.get(st)\n",
    "            browser.implicitly_wait(5)\n",
    "            \n",
    "            html = urlopen(st)\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            #  save the html content as a string\n",
    "            string = str(soup)\n",
    "\n",
    "            # find all the bold texts in the page\n",
    "            name = soup.findAll('b')\n",
    "\n",
    "            # flag to identify whether the bold text is a new name or modified version of the old name\n",
    "            # Here I use the fact that new names appear only after the religion name is mentioned in the bold text\n",
    "            flag = 1\n",
    "            \n",
    "            # list of all politician names found on the religion by state webpage\n",
    "            pol_list=[]\n",
    "\n",
    "            # loop over all the bold text tags\n",
    "            for each in name:\n",
    "\n",
    "                # if the text contains the word 'Political', it means that all the names have been scraped\n",
    "                if('Political' in each.text):\n",
    "                    break\n",
    "\n",
    "                # if next bold tag is a new name, flag = 1\n",
    "                if flag==1:\n",
    "                    if ('(' in each.text):\n",
    "                        # if text contains info on birth/death year in (), remove that and save the data\n",
    "                        pol_list.append(each.text[0:each.text.find('(')])\n",
    "                    else: \n",
    "                        pol_list.append(each.text)\n",
    "\n",
    "                    # next tag will not be a new name\n",
    "                    flag = 0\n",
    "\n",
    "                elif (rel in each.text):\n",
    "                    # if the bold tag contains a religion name, the next bold tag will have a new name\n",
    "                    flag = 1\n",
    "\n",
    "            # locate the positions of all the politician names in the text of the html content\n",
    "            locate=[]\n",
    "            for each in pol_list:\n",
    "                locate.append(string.find(each))\n",
    "\n",
    "            # find the length of 'locate' list\n",
    "            l = len(locate)\n",
    "            for x in np.arange(l):\n",
    "                if x<=l-2:\n",
    "                    # read the substring of 'string' as an html file through BeautifulSoup\n",
    "                    soup = BeautifulSoup(string[locate[x]:locate[x+1]],features=\"html.parser\")\n",
    "                    for each in (soup.find_all('a')): # for each link in the substring\n",
    "                        if 'born' in each.get('href'): # if the link is a 'born' link\n",
    "                            temp1 = string[locate[x]:locate[x+1]].find(each.get_text()) # index of the link in the substring\n",
    "                            temp2 = string[locate[x]:locate[x+1]].find('/a>',temp1)+5 # index of '/a>' after the link in the substring\n",
    "                            temp3 = string[locate[x]:locate[x+1]].find('<a',temp2) # index of '<a' after '/a>' in the substring\n",
    "                            temp4 = string[locate[x]:locate[x+1]][temp2:temp3].replace('\\n', ' ') \n",
    "                            # extract the born state name located between temp2 and temp3 by replacing the '\\n' with ' '\n",
    "\n",
    "                            dic_pol_name_state_rel[count] = {'lived_state':state, 'born_state':temp4[:temp4.rfind(',')], 'born_county':each.get_text().replace('\\n', ' '), 'religion':rel, 'pol_name':pol_list[x] }\n",
    "                            count +=1\n",
    "\n",
    "                elif x ==l-1: # if it is the last name in the list of politicians for that state\n",
    "                    # read the substring of 'string' as an html file through BeautifulSoup\n",
    "                    soup = BeautifulSoup(string[locate[x]:],features=\"html.parser\")\n",
    "                    for each in (soup.find_all('a')):  # for each link in the substring\n",
    "                        if 'born' in each.get('href'): # if the link is a 'born' link\n",
    "                            temp1 = string[locate[x]:].find(each.get_text()) # index of the link in the substring\n",
    "                            temp2 = string[locate[x]:].find('/a>',temp1)+5 # index of '/a>' after the link in the substring\n",
    "                            temp3 = string[locate[x]:].find('<a',temp2) # index of '<a' after '/a>' in the substring\n",
    "                            temp4 = string[locate[x]:][temp2:temp3].replace('\\n', ' ')\n",
    "                            # extract the born state name located between temp2 and temp3 by replacing the '\\n' with ' '\n",
    "\n",
    "                            dic_pol_name_state_rel[count] = {'lived_state':state, 'born_state':temp4[:temp4.rfind(',')], 'born_county':each.get_text().replace('\\n', ' '), 'religion':rel, 'pol_name':pol_list[x] }\n",
    "                            count +=1\n",
    "    \n",
    "            # Some state's have their counties clubbed alphabetically A-C, D-F etc...\n",
    "\n",
    "            html = urlopen(st)\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            # find all the links in that state's webpage\n",
    "            link = soup.findAll('a')\n",
    "\n",
    "            # create a list of links containing the links to all the clubbed pages\n",
    "            ord = []\n",
    "\n",
    "            # if next bold tag is a new name, flag = 1\n",
    "            flag = 0\n",
    "\n",
    "            for each in link:\n",
    "                # based on the link texts, identify the useful links that have the names of politians \n",
    "                if (('to' in each.get_text()) & ('zz' in each.get_text()) & ('geo' in each.get('href'))):\n",
    "                    # save the links into the list\n",
    "                    ord.append(each.get(\"href\"))\n",
    "                    flag = 1\n",
    "\n",
    "            # if such kind of clubbing exists on ghe webpage, then run this part of the code\n",
    "            if (flag == 1):\n",
    "                # loop over all the links stored in the list above\n",
    "                for curr in ord:\n",
    "\n",
    "                    # open each link\n",
    "                    html = urlopen(curr)\n",
    "                    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "                    #  save the html content as a string\n",
    "                    string = str(soup)\n",
    "\n",
    "                    # list of all politician names found on the religion by state webpage\n",
    "                    pol_list=[]\n",
    "\n",
    "                    # find all the bold tags\n",
    "                    name=soup.findAll('b')\n",
    "\n",
    "                    # for each bold tag, check if it has a new name\n",
    "                    for each in name:\n",
    "                        \n",
    "                        # if the word 'Political' appears in a new bold tag, it means all the new names have been scraped\n",
    "                        # so break\n",
    "                        if('Political' in each.text):\n",
    "                            break\n",
    "\n",
    "                        # if the next bold tag has a new name\n",
    "                        if flag==1:\n",
    "                            if ('(' in each.text):\n",
    "                                # if text contains info on birth/death year in (), remove that and save the data\n",
    "                                pol_list.append(each.text[0:each.text.find('(')])\n",
    "                            else: \n",
    "                                pol_list.append(each.text)\n",
    "\n",
    "\n",
    "                            # the next bold tag does not contain a new name\n",
    "                            flag = 0\n",
    "\n",
    "                        elif (rel in each.text):\n",
    "                            # if this tag has a religion name, the next bold tag has a new name\n",
    "                            flag = 1\n",
    "                            \n",
    "                    # locate the positions of all the politician names in the text of the html content\n",
    "                    locate=[]\n",
    "                    for each in pol_list:\n",
    "                        locate.append(string.find(each))\n",
    "\n",
    "                    l = len(locate)\n",
    "                    for x in np.arange(l):\n",
    "                        if x<=l-2:\n",
    "                            soup = BeautifulSoup(string[locate[x]:locate[x+1]],features=\"html.parser\")\n",
    "                            for each in (soup.find_all('a')):\n",
    "                                if 'born' in each.get('href'): # if the link is a 'born' link\n",
    "                                    temp1 = string[locate[x]:locate[x+1]].find(each.get_text()) # index of the link in the substring\n",
    "                                    temp2 = string[locate[x]:locate[x+1]].find('/a>',temp1)+5 # index of '/a>' after the link in the substring\n",
    "                                    temp3 = string[locate[x]:locate[x+1]].find('<a',temp2) # index of '<a' after '/a>' in the substring\n",
    "                                    temp4 = string[locate[x]:locate[x+1]][temp2:temp3].replace('\\n', ' ') \n",
    "                                    # extract the born state name located between temp2 and temp3 by replacing the '\\n' with ' '\n",
    "\n",
    "                                    dic_pol_name_state_rel[count] = {'lived_state':state, 'born_state':temp4[:temp4.rfind(',')], 'born_county':each.get_text().replace('\\n', ' '), 'religion':rel, 'pol_name':pol_list[x] }\n",
    "                                    count +=1\n",
    "\n",
    "                        elif x ==l-1: # if it is the last name in the list of politicians for that state\n",
    "                            # read the substring of 'string' as an html file through BeautifulSoup\n",
    "                            soup = BeautifulSoup(string[locate[x]:],features=\"html.parser\")\n",
    "                            for each in (soup.find_all('a')):  # for each link in the substring\n",
    "                                if 'born' in each.get('href'): # if the link is a 'born' link\n",
    "                                    temp1 = string[locate[x]:].find(each.get_text()) # index of the link in the substring\n",
    "                                    temp2 = string[locate[x]:].find('/a>',temp1)+5 # index of '/a>' after the link in the substring\n",
    "                                    temp3 = string[locate[x]:].find('<a',temp2) # index of '<a' after '/a>' in the substring\n",
    "                                    temp4 = string[locate[x]:][temp2:temp3].replace('\\n', ' ')\n",
    "                                    # extract the born state name located between temp2 and temp3 by replacing the '\\n' with ' '\n",
    "\n",
    "                                    dic_pol_name_state_rel[count] = {'lived_state':state, 'born_state':temp4[:temp4.rfind(',')], 'born_county':each.get_text().replace('\\n', ' '), 'religion':rel, 'pol_name':pol_list[x] }\n",
    "                                    count +=1\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Selenium for web-scraping\n",
    "EXE_PATH = r'C:\\Users\\nikhi\\Desktop\\Summer 2020\\RA Work\\Scraping\\chromedriver.exe'\n",
    "browser = webdriver.Chrome(executable_path=EXE_PATH)\n",
    "\n",
    "# loop over each religion\n",
    "for rel in religion2:\n",
    "\n",
    "    url = \"http://politicalgraveyard.com/index.html#PE\"\n",
    "    \n",
    "    # open each URL in the webpage\n",
    "    browser.get(url)\n",
    "    browser.implicitly_wait(5)\n",
    "\n",
    "    # click on the link containing the religion name in text\n",
    "    rel_link = browser.find_element_by_link_text(rel).click()\n",
    "    rel_url = browser.current_url\n",
    "\n",
    "    html = urlopen(rel_url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    # find all the link in the religion webpage\n",
    "    link = soup.findAll('a')\n",
    "\n",
    "    try:\n",
    "            browser.get(rel_url)\n",
    "            browser.implicitly_wait(5)\n",
    "            \n",
    "            html = urlopen(rel_url)\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            #  save the html content as a string\n",
    "            string = str(soup)\n",
    "\n",
    "            # list of all politician names found on the religion by state webpage\n",
    "            pol_list=[]\n",
    "\n",
    "            # find all the bold tags in the religion webpage\n",
    "            name = soup.findAll('b')\n",
    "\n",
    "            # flag to identify if the next bold tag contains a new name\n",
    "            flag = 1\n",
    "            \n",
    "            # loop over each bold tag in the webpage\n",
    "            for each in name:\n",
    "\n",
    "                # if 'political' appears in the bold tag, it means all the names have been scraped\n",
    "                if('Political' in each.text):\n",
    "                    break\n",
    "\n",
    "                # if the next tag contains a new name, store the name\n",
    "                if flag==1:\n",
    "                    if ('(' in each.text):\n",
    "                        # if name has info on birth/death year, then remove that info by substring accordingly\n",
    "                        pol_list.append(each.text[0:each.text.find('(')])\n",
    "                    else: \n",
    "                        pol_list.append(each.text)\n",
    "\n",
    "                    # next bold tage is not a new name\n",
    "                    flag = 0\n",
    "\n",
    "                elif (rel in each.text):\n",
    "                    # if this tag has religion name, next bold tag has a new name\n",
    "                    flag = 1\n",
    "\n",
    "            #locate the positions of all the politician names in the text of the html content\n",
    "            locate=[]\n",
    "            for each in pol_list:\n",
    "                locate.append(string.find(each))\n",
    "        \n",
    "            l = len(locate)\n",
    "            for x in np.arange(l):\n",
    "                if x<=l-2:\n",
    "                    soup = BeautifulSoup(string[locate[x]:locate[x+1]],features=\"html.parser\")\n",
    "                    for each in (soup.find_all('a')):\n",
    "                        if 'born' in each.get('href'): # if the link is a 'born' link\n",
    "                            temp1 = string[locate[x]:locate[x+1]].find(each.get_text()) # index of the link in the substring\n",
    "                            temp2 = string[locate[x]:locate[x+1]].find('/a>',temp1)+5 # index of '/a>' after the link in the substring\n",
    "                            temp3 = string[locate[x]:locate[x+1]].find('<a',temp2) # index of '<a' after '/a>' in the substring\n",
    "                            temp4 = string[locate[x]:locate[x+1]][temp2:temp3].replace('\\n', ' ') \n",
    "                            # extract the born state name located between temp2 and temp3 by replacing the '\\n' with ' '\n",
    "\n",
    "                            dic_pol_name_state_rel[count] = {'lived_state':state, 'born_state':temp4[:temp4.rfind(',')], 'born_county':each.get_text().replace('\\n', ' '), 'religion':rel, 'pol_name':pol_list[x] }\n",
    "                            count +=1\n",
    "\n",
    "                elif x ==l-1: # if it is the last name in the list of politicians for that state\n",
    "                    # read the substring of 'string' as an html file through BeautifulSoup\n",
    "                    soup = BeautifulSoup(string[locate[x]:],features=\"html.parser\")\n",
    "                    for each in (soup.find_all('a')):  # for each link in the substring\n",
    "                        if 'born' in each.get('href'): # if the link is a 'born' link\n",
    "                            temp1 = string[locate[x]:].find(each.get_text()) # index of the link in the substring\n",
    "                            temp2 = string[locate[x]:].find('/a>',temp1)+5 # index of '/a>' after the link in the substring\n",
    "                            temp3 = string[locate[x]:].find('<a',temp2) # index of '<a' after '/a>' in the substring\n",
    "                            temp4 = string[locate[x]:][temp2:temp3].replace('\\n', ' ')\n",
    "                            # extract the born state name located between temp2 and temp3 by replacing the '\\n' with ' '\n",
    "\n",
    "                            dic_pol_name_state_rel[count] = {'lived_state':state, 'born_state':temp4[:temp4.rfind(',')], 'born_county':each.get_text().replace('\\n', ' '), 'religion':rel, 'pol_name':pol_list[x] }\n",
    "                            count +=1\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'dic_pol_name_state_rel' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2e17f6518edd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# save the dictionary into a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_pol_name_state_rel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdic_pol_name_state_rel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# save the dataframe into an excel file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_pol_name_state_rel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data_state_county_religion.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'xlsxwriter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dic_pol_name_state_rel' is not defined"
     ]
    }
   ],
   "source": [
    "# save the dictionary into a dataframe\n",
    "df_pol_name_state_rel=pd.DataFrame.from_dict(dic_pol_name_state_rel).T\n",
    "\n",
    "# save the dataframe into an excel file\n",
    "df_pol_name_state_rel.to_excel('data_state_county_religion.xlsx',engine='xlsxwriter')"
   ]
  },
  {
   "source": [
    "### Change the name of birth state from abbreviated to its full name"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# open an excel file that abbreviations for US state names into dataframe\n",
    "df_st = pd.read_excel('state_name_abb.xlsx')\n",
    "df_st['ABB'] = df_st['ABB'].str.replace(' ','')\n",
    "df_pol_name_state_rel = pd.read_excel(\"data_state_county_religion.xlsx\")\n",
    "for abb in df_pol_name_state_rel['born_state']:\n",
    "    # for each abbreviation in the clergy names dataframe\n",
    "    flag = 0\n",
    "    for each in df_st['ABB']:\n",
    "        if str(each) in str(abb):\n",
    "            # if part of the state name is in an actual state name\n",
    "            # replace the state name (abbreviated) to full state name\n",
    "            temp = df_st.loc[df_st['ABB']==each].iloc[0,0]\n",
    "            df_pol_name_state_rel['born_state'] = df_pol_name_state_rel['born_state'].replace(abb, temp)\n",
    "            flag = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe into an excel file\n",
    "df_pol_name_state_rel.to_excel('data_state_county_religion_final.xlsx',engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Unnamed: 0 lived_state                           born_state  \\\n",
       "0               0     Alabama                              Alabama   \n",
       "1               1     Alabama                              Alabama   \n",
       "2               2     Alabama                              Alabama   \n",
       "3               3     Alabama                              Alabama   \n",
       "4               4     Alabama                              Alabama   \n",
       "...           ...         ...                                  ...   \n",
       "20176       20176        none  second cousin five times removed of   \n",
       "20177       20177        none                             Virginia   \n",
       "20178       20178        none                             Michigan   \n",
       "20179       20179        none                             Delaware   \n",
       "20180       20180        none                             New York   \n",
       "\n",
       "              born_county       religion                   pol_name  \n",
       "0        Jefferson County      Methodist  Oscar William Adams, Jr.   \n",
       "1          Winston County      Methodist     Robert Brown Aderholt   \n",
       "2           Blount County      Methodist     Miles Clayton Allgood   \n",
       "3         Lawrence County      Methodist       Edward Berton Almon   \n",
       "4           Mobile County      Methodist      Julian Leigh Andrews   \n",
       "...                   ...            ...                        ...  \n",
       "20176     Lithgow Osborne          Deist         Benjamin Franklin   \n",
       "20177    Albemarle County          Deist          Thomas Jefferson   \n",
       "20178        Wayne County  Scientologist                Sonny Bono   \n",
       "20179   New Castle County  Scientologist          Stephen A. Davis   \n",
       "20180  Schenectady County          Hindu            Kumar P. Barve   \n",
       "\n",
       "[20181 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>lived_state</th>\n      <th>born_state</th>\n      <th>born_county</th>\n      <th>religion</th>\n      <th>pol_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Alabama</td>\n      <td>Alabama</td>\n      <td>Jefferson County</td>\n      <td>Methodist</td>\n      <td>Oscar William Adams, Jr.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Alabama</td>\n      <td>Alabama</td>\n      <td>Winston County</td>\n      <td>Methodist</td>\n      <td>Robert Brown Aderholt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Alabama</td>\n      <td>Alabama</td>\n      <td>Blount County</td>\n      <td>Methodist</td>\n      <td>Miles Clayton Allgood</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Alabama</td>\n      <td>Alabama</td>\n      <td>Lawrence County</td>\n      <td>Methodist</td>\n      <td>Edward Berton Almon</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Alabama</td>\n      <td>Alabama</td>\n      <td>Mobile County</td>\n      <td>Methodist</td>\n      <td>Julian Leigh Andrews</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20176</th>\n      <td>20176</td>\n      <td>none</td>\n      <td>second cousin five times removed of</td>\n      <td>Lithgow Osborne</td>\n      <td>Deist</td>\n      <td>Benjamin Franklin</td>\n    </tr>\n    <tr>\n      <th>20177</th>\n      <td>20177</td>\n      <td>none</td>\n      <td>Virginia</td>\n      <td>Albemarle County</td>\n      <td>Deist</td>\n      <td>Thomas Jefferson</td>\n    </tr>\n    <tr>\n      <th>20178</th>\n      <td>20178</td>\n      <td>none</td>\n      <td>Michigan</td>\n      <td>Wayne County</td>\n      <td>Scientologist</td>\n      <td>Sonny Bono</td>\n    </tr>\n    <tr>\n      <th>20179</th>\n      <td>20179</td>\n      <td>none</td>\n      <td>Delaware</td>\n      <td>New Castle County</td>\n      <td>Scientologist</td>\n      <td>Stephen A. Davis</td>\n    </tr>\n    <tr>\n      <th>20180</th>\n      <td>20180</td>\n      <td>none</td>\n      <td>New York</td>\n      <td>Schenectady County</td>\n      <td>Hindu</td>\n      <td>Kumar P. Barve</td>\n    </tr>\n  </tbody>\n</table>\n<p>20181 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_pol_name_state_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitc93c2ab14bb54a9e898317ef2f21e286",
   "display_name": "Python 3.7.7 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}